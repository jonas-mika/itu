{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"frontmatter text-center\">\n",
    "<h1> Introduction to Data Science and Programming</h1>\n",
    "<h2>Lecture 26: The data science process</h2>\n",
    "<h3>IT University of Copenhagen, Fall 2020</h3>\n",
    "<h3>Instructor: Michael Szell</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Source\n",
    "This notebook was adapted from:\n",
    "* Joel Grus: Data Science from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pprint as pp # pretty print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing csv files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading a clean data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6/20/2014,AAPL,90.91\n6/20/2014,MSFT,41.68\n6/20/2014,FB,64.5\n6/19/2014,AAPL,91.86\n6/19/2014,MSFT,41.51\n6/19/2014,FB,64.34"
     ]
    }
   ],
   "source": [
    "!head files/stockprices.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's read this with the simplest way (using csv.reader):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[['6/20/2014', 'AAPL', 90.91],\n ['6/20/2014', 'MSFT', 41.68],\n ['6/20/2014', 'FB', 64.5],\n ['6/19/2014', 'AAPL', 91.86],\n ['6/19/2014', 'MSFT', 41.51],\n ['6/19/2014', 'FB', 64.34]]\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "with open('files/stockprices.csv', 'r') as f: \n",
    "    reader = csv.reader(f, delimiter=',')\n",
    "    for row in reader:\n",
    "        date = row[0]\n",
    "        symbol = row[1]\n",
    "        closing_price = float(row[2]) \n",
    "        data.append([date,symbol,closing_price])\n",
    "pp.pprint(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we did not parse the first two columns in any special way, meaning we just read them in as strings. The last column we read in as `float`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is OK to read a date as a string, but if we want to do any operations with them (like which date was before or after, how many days are in-between, etc), we would need to convert them into some numeric values, writing our own parser like in lecture 7. Somebody already wrote a good date parser (`dateutil.parser`), so let's use that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[datetime.datetime(2014, 6, 20, 0, 0), 'AAPL', 90.91],\n [datetime.datetime(2014, 6, 20, 0, 0), 'MSFT', 41.68],\n [datetime.datetime(2014, 6, 20, 0, 0), 'FB', 64.5],\n [datetime.datetime(2014, 6, 19, 0, 0), 'AAPL', 91.86],\n [datetime.datetime(2014, 6, 19, 0, 0), 'MSFT', 41.51],\n [datetime.datetime(2014, 6, 19, 0, 0), 'FB', 64.34]]\n"
     ]
    }
   ],
   "source": [
    "from dateutil.parser import parse\n",
    "data = []\n",
    "with open('files/stockprices.csv', 'r') as f: \n",
    "    reader = csv.reader(f, delimiter=',')\n",
    "    for row in reader:\n",
    "        date = parse(row[0])\n",
    "        symbol = row[1]\n",
    "        closing_price = float(row[2]) \n",
    "        data.append([date,symbol,closing_price])\n",
    "pp.pprint(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have nice datetime objects that come with all kind of methods, and we can do all kinds of operations with them, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1 day, 0:00:00\n"
     ]
    }
   ],
   "source": [
    "first_time = data[3][0]\n",
    "later_time = data[2][0]\n",
    "difference = later_time - first_time\n",
    "print(difference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading a \"dirty\" data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is *very* common to not start with a \"clean\" data set, but with something that is \"dirty\". For example, one value could have a different data type than other values of the same attribute, like the `n/a` here which stands for a missing value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6/20/2014,AAPL,90.91\n6/20/2014,MSFT,41.68\n6/20/2014,FB,64.5\n6/19/2014,AAPL,91.86\n6/19/2014,MSFT,n/a\n6/19/2014,FB,64.34"
     ]
    }
   ],
   "source": [
    "!head files/stockprices_missing.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we use the code from above, it will crash because it cannot turn `n/a` into a `float`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'n/a'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-86b7b1b1b134>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mdate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0msymbol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mclosing_price\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msymbol\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclosing_price\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mpp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'n/a'"
     ]
    }
   ],
   "source": [
    "from dateutil.parser import parse\n",
    "data = []\n",
    "with open('files/stockprices_missing.csv', 'r') as f: \n",
    "    reader = csv.reader(f, delimiter=',')\n",
    "    for row in reader:\n",
    "        date = parse(row[0])\n",
    "        symbol = row[1]\n",
    "        closing_price = float(row[2]) \n",
    "        data.append([date,symbol,closing_price])\n",
    "pp.pprint(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To account for malformed data like this, we could introduce `if` clauses into our code above and check explicitly for specific problems. But there is a more general way to handle this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementing a parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's re-write our parsing problem by using functions that parse rows, telling how to parse each column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_row(input_row, parsers):\n",
    "    \"\"\"given a list of parsers (some of which may be None)\n",
    "apply the appropriate one to each element of the input_row\"\"\"\n",
    "    return [parser(value) if parser is not None else value for value, parser in zip(input_row, parsers)]\n",
    "\n",
    "def parse_rows_with(reader, parsers):\n",
    "    \"\"\"wrap a reader to apply the parsers to each of its rows\"\"\"\n",
    "    for row in reader:\n",
    "        yield parse_row(row, parsers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It works for our nice data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[datetime.datetime(2014, 6, 20, 0, 0), 'AAPL', 90.91],\n [datetime.datetime(2014, 6, 20, 0, 0), 'MSFT', 41.68],\n [datetime.datetime(2014, 6, 20, 0, 0), 'FB', 64.5],\n [datetime.datetime(2014, 6, 19, 0, 0), 'AAPL', 91.86],\n [datetime.datetime(2014, 6, 19, 0, 0), 'MSFT', 41.51],\n [datetime.datetime(2014, 6, 19, 0, 0), 'FB', 64.34]]\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "with open(\"files/stockprices.csv\", \"r\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    for line in parse_rows_with(reader, [parse, None, float]):\n",
    "        data.append(line)\n",
    "pp.pprint(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But it does not work for our bad data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'n/a'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-8b259c326982>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"files/stockprices_missing.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparse_rows_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mpp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-49faf1782dcf>\u001b[0m in \u001b[0;36mparse_rows_with\u001b[0;34m(reader, parsers)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;34m\"\"\"wrap a reader to apply the parsers to each of its rows\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0;32myield\u001b[0m \u001b[0mparse_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-49faf1782dcf>\u001b[0m in \u001b[0;36mparse_row\u001b[0;34m(input_row, parsers)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \"\"\"given a list of parsers (some of which may be None)\n\u001b[1;32m      3\u001b[0m apply the appropriate one to each element of the input_row\"\"\"\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mparser\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparser\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_row\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mparse_rows_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-49faf1782dcf>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \"\"\"given a list of parsers (some of which may be None)\n\u001b[1;32m      3\u001b[0m apply the appropriate one to each element of the input_row\"\"\"\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mparser\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparser\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_row\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mparse_rows_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'n/a'"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "with open(\"files/stockprices_missing.csv\", \"r\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    for line in parse_rows_with(reader, [parse, None, float]):\n",
    "        data.append(line)\n",
    "pp.pprint(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding a helper function with a try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_or_none(f):\n",
    "    \"\"\"Wraps f to return None if f raises an exception. \n",
    "    Assumes f takes only one input.\"\"\"\n",
    "    def f_or_none(x):\n",
    "        try: return f(x)\n",
    "        except: return None \n",
    "    return f_or_none\n",
    "\n",
    "# Let's re-define our parse_row function, adding the try_or_none part:\n",
    "def parse_row(input_row, parsers):\n",
    "    return [try_or_none(parser)(value) if parser is not None else value\n",
    "for value, parser in zip(input_row, parsers)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it should work, and the bad piece of data will be read in as `None`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[datetime.datetime(2014, 6, 20, 0, 0), 'AAPL', 90.91],\n [datetime.datetime(2014, 6, 20, 0, 0), 'MSFT', 41.68],\n [datetime.datetime(2014, 6, 20, 0, 0), 'FB', 64.5],\n [datetime.datetime(2014, 6, 19, 0, 0), 'AAPL', 91.86],\n [datetime.datetime(2014, 6, 19, 0, 0), 'MSFT', None],\n [datetime.datetime(2014, 6, 19, 0, 0), 'FB', 64.34]]\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "with open(\"files/stockprices_missing.csv\", \"r\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    for line in parse_rows_with(reader, [parse, None, float]):\n",
    "        data.append(line)\n",
    "pp.pprint(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking and deciding what to do with the bad data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last step is now to investigate whether/where we have `None`s and decide what to do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[datetime.datetime(2014, 6, 19, 0, 0), 'MSFT', None]\n"
     ]
    }
   ],
   "source": [
    "for row in data:\n",
    "    if any(x is None for x in row):\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally speaking, we have now three options:\n",
    "1. get rid of this row\n",
    "2. go back to the source and try to fix the bad/missing data\n",
    "3. do nothing and cross our fingers\n",
    "\n",
    "In any case, if we want our analysis to be reproducible, we *must* document what we did, and we must keep the original data set so that the cleaning and analysis can be run again the same way, leading to the same results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that libraries like `pandas` have several data cleaning features built-in, like the ones developed above from scratch, which can make your life easier. Still, many data sets or problems require their unique solutions, so often you cannot rely on a standardized library or approach. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}