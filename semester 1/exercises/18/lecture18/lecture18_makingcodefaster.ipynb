{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"frontmatter text-center\">\n",
    "<h1> Introduction to Data Science and Programming</h1>\n",
    "<h2>Lecture 18: Making code faster</h2>\n",
    "<h3>IT University of Copenhagen, Fall 2020</h3>\n",
    "    <h3>Instructor: Michael Szell</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Source\n",
    "This notebook was adapted from:\n",
    "* https://towardsdatascience.com/speed-up-jupyter-notebooks-20716cbe2025\n",
    "* https://jakevdp.github.io/PythonDataScienceHandbook/01.07-timing-and-profiling.html\n",
    "* https://people.duke.edu/~ccc14/sta-663/MakingCodeFast.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Premature Optimization Is the Root of All Evil\n",
    "\n",
    "Donald Knuth: *Programmers waste enormous amounts of time thinking about, or worrying about, the speed of noncritical parts of their programs, and these attempts at efficiency actually have a strong negative impact when debugging and maintenance are considered. We should forget about small efficiencies, say about 97% of the time: premature optimization is the root of all evil. Yet we should not pass up our opportunities in that critical 3%.*\n",
    "\n",
    "Correct order of steps when writing a program:\n",
    "1. **Make it work**: Write the code in a simple legible way.\n",
    "2. **Make it right**: Write test cases, make really sure that your algorithm is right and that if you break it, the tests will capture the breakage.\n",
    "3. **Make it fast**: Optimize the code by profiling simple use-cases to find the bottlenecks and speeding up these bottlenecks, finding a better algorithm or implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Making it fast is the LAST step\n",
    "and you should only optimize when it is necessary. Also, it is good to know when a program is “fast enough” for your needs. Optimization has a price:\n",
    "\n",
    "* Cost in programmer time\n",
    "* Optimized code is often more complex\n",
    "* Optimized code is often less generic\n",
    "\n",
    "However, having fast code is often necessary for statistical computing, so we will spend some time learning how to make code run faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Super-advanced example of code optimization: Fast inverse square root\n",
    "3D-games and simulators need billions of real-time inverse square root $\\frac{1}{\\sqrt{x}}$ calculations for lighting and shading:\n",
    "<img src=\"files/surfacenormal.png\" width=220px> <img src=\"files/openarena.jpg\" width=220px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of doing `(float)(1.0/sqrt(x))`, this C++ code was developed in the 1980s/1990s (original comments):\n",
    "\n",
    "```c++\n",
    "float Q_rsqrt( float number )\n",
    "{\n",
    "\tlong i;\n",
    "\tfloat x2, y;\n",
    "\tconst float threehalfs = 1.5F;\n",
    "\n",
    "\tx2 = number * 0.5F;\n",
    "\ty  = number;\n",
    "\ti  = * ( long * ) &y;                       // evil floating point bit level hacking\n",
    "\ti  = 0x5f3759df - ( i >> 1 );               // what the fuck? \n",
    "\ty  = * ( float * ) &i;\n",
    "\ty  = y * ( threehalfs - ( x2 * y * y ) );   // 1st iteration\n",
    "//\ty  = y * ( threehalfs - ( x2 * y * y ) );   // 2nd iteration, this can be removed\n",
    "\n",
    "\treturn y;\n",
    "}\n",
    "```\n",
    "\n",
    "It avoids division and is 4 times faster. This is a significant speed-up for millions of real-time calculations every second.\n",
    "More details: \n",
    "https://en.wikipedia.org/wiki/Fast_inverse_square_root\n",
    "\n",
    "https://betterexplained.com/articles/understanding-quakes-fast-inverse-square-root/\n",
    "\n",
    "Warning - advanced math: http://www.lomont.org/papers/2003/InvSqrt.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Code can be slow for different reasons\n",
    "\n",
    "* **CPU-bound** - CPU is working flat out\n",
    "* **Memory-bound** - Out of RAM - swapping to hard disk\n",
    "* **IO-bound** - Lots of data transfer to and from hard disk\n",
    "* **Network-bound** - CPU is waiting for data to come over network or from memory (“starvation”)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## There is a natural order of making code fast\n",
    "1. Cheat: Use sample data, solve a simpler problem, buy more RAM, etc.\n",
    "2. **Profile**: Find out the bottlenecks\n",
    "3. **Use better algorithms and data structures**\n",
    "4. Using compiled code written in another language\n",
    "5. Converting Python code to compiled code\n",
    "6. Parallelize programs / execute in parallel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Profiling and timing code\n",
    "There is no optimization without measuring! Do not rely on \"theorycrafting\" - just measure it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Magic commands for Jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `%time`: Time the execution of a single statement\n",
    "* `%timeit`: Time repeated execution of a single statement for more accuracy\n",
    "* `%prun`: Run code with the profiler\n",
    "* `%lprun`: Run code with the line-by-line profiler\n",
    "* `%memit`: Measure the memory use of a single statement\n",
    "* `%mprun`: Run code with the line-by-line memory profiler\n",
    "\n",
    "The last 3 commands are not bundled with Jupyter – you'll need to get the `line_profiler` and `memory_profiler` extension.\n",
    "\n",
    "Also we use:\n",
    "\n",
    "* `%%heat`\n",
    "* `snakeviz`: visualizing the output of a profiling session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Timing Code Snippets: ``%timeit`` and ``%time``\n",
    "\n",
    "The ``%timeit`` line-magic and ``%%timeit`` cell-magic can be used to time the repeated execution of snippets of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit sum(range(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because this operation is so fast, ``%timeit`` automatically does a large number of repetitions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For slower commands, ``%timeit`` will automatically adjust and perform fewer repetitions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "total = 0\n",
    "for i in range(1000):\n",
    "    for j in range(1000):\n",
    "        total += i * (-1) ** j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Sometimes repeating an operation is not the best option.\n",
    "For example, if we have a list that we'd like to sort, we might be misled by a repeated operation.\n",
    "Sorting a pre-sorted list is much faster than sorting an unsorted list, so the repetition will skew the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "L = [random.random() for i in range(100000)]\n",
    "%timeit L.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For this, the ``%time`` magic function may be a better choice. It also is a good choice for longer-running commands, when short, system-related delays are unlikely to affect the result.\n",
    "Let's time the sorting of an unsorted and a presorted list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "L = [random.random() for i in range(100000)]\n",
    "print(\"sorting an unsorted list:\")\n",
    "%time L.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"sorting an already sorted list:\")\n",
    "%time L.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Wall time is the time that a clock on the wall would measure as having elapsed between the start of the process and 'now'.\n",
    "\n",
    "The CPU times is the amount of time spent of the CPUs (can be much more than wall time if multi-core, for example)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The presorted list is much faster to sort. Notice also how much longer the timing takes with ``%time`` versus ``%timeit``, even for the presorted list! ``%timeit`` does some clever things under the hood to prevent system calls from interfering with the timing. For this reason, ``%timeit`` results are usually noticeably faster than ``%time`` results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For ``%time`` as with ``%timeit``, using the double-percent-sign cell magic syntax allows timing of multiline scripts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "total = 0\n",
    "for i in brange(1000):\n",
    "    for j in range(1000):\n",
    "        total += i * (-1) ** j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information on ``%time`` and ``%timeit``, as well as their available options, use the IPython help functionality (i.e., type ``%time?`` at the IPython prompt)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Timing outside of Jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "\n",
    "start = timer()\n",
    "sum(range(100))\n",
    "end = timer()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "start = time.perf_counter()\n",
    "sum(range(100))\n",
    "end = time.perf_counter()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Profiling and Optimizing: Monte Carlo method example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get the value of pi by taking the ratio of area of circle to area of the square:\n",
    "<img src=\"files/montecarlo01.png\" width=400px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "where we approximate the area with generated random points, $\\frac{\\mathrm{area\\, of\\, circle}}{\\mathrm{area\\, of\\, square}} \\approx \\frac{\\mathrm{points\\, in\\, circle}}{\\mathrm{points\\, in\\, square}}$\n",
    "<img src=\"files/montecarlo02.png\" width=400px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from random import random\n",
    "\n",
    "def estimate_pi(n = 10000000):\n",
    "    \"\"\"Estimate pi with monte carlo simulation.\"\"\"\n",
    "    in_circle = 0\n",
    "    total = n\n",
    "    \n",
    "    while n != 0:\n",
    "        prec_x = random()\n",
    "        prec_y = random()\n",
    "        if pow(prec_x, 2) + pow(prec_y, 2) <= 1: # circle equation: x^2+y^2=r^2\n",
    "            in_circle += 1 # inside the circle\n",
    "        n -= 1\n",
    "        \n",
    "    return 4 * in_circle / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%time estimate_pi()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From now on, lets normalize this and run `%timeit` always with the same parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -r 2 -n 5 estimate_pi()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### cProfile\n",
    "To learn what takes up most of the execution time, python ships with a great profiler, cProfile, breaking down the execution function by function. It causes our attention to shrink down to critical functions by handing out a high-level view of performance. In Jupyer, use the [`%prun`](https://ipython.readthedocs.io/en/stable/interactive/magics.html#magic-prun) magic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%prun estimate_pi()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The output will be written to stdout:<img src=\"files/profiling.png\" width=1000>\n",
    "\n",
    "The report shows for each function:\n",
    "* the number of calls (ncalls)\n",
    "* the total time (tottime) spent on it excluding calls to subfunctions\n",
    "* how long each call took (percall, excluding and including)\n",
    "* the total time (cumtime) including all calls to subfunctions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "An another useful option is -s which enables sorting for a particular column. For example sorting cumulative time in descending order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%prun -s cumulative estimate_pi()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If we wish to save the output for later inspection for example with [pstats](https://docs.python.org/3.7/library/profile.html#the-stats-class), use the -D option to save on disk. \n",
    "\n",
    "You can also just return the stats object with the -r option:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = %prun -r -q estimate_pi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.sort_stats('tottime').print_stats(3);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of calls to built-in functions `pow()` and `random()` seems to take some time. Before we address this extensive number of calls, let’s have a look at a much more convenient library delivering even more concrete reports."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Line profiler\n",
    "The `%lprun` command yields the time spent on each line of code giving us a line by line report. Since not shipped by default, install the library\n",
    "\n",
    "```bash\n",
    "conda install line_profiler \n",
    "```\n",
    "\n",
    "and load the extension manually in the notebook.\n",
    "\n",
    "```python\n",
    "%load_ext line_profiler\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_lprun = %lprun -r -f estimate_pi estimate_pi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "stats_lprun.print_stats();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the extensive time (~28%) spent on the if statement on line 15."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Visualizing the profile with heat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "pip install py-heat-magic\n",
    "```\n",
    "\n",
    "and load the extension manually in the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext heat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code can take a minute or two to execute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%%heat\n",
    "from random import random\n",
    "def estimate_pi(n = 10000000):\n",
    "    in_circle = 0\n",
    "    total = n\n",
    "    \n",
    "    while n != 0:\n",
    "        prec_x = random()\n",
    "        prec_y = random()\n",
    "        if pow(prec_x, 2) + pow(prec_y, 2) <= 1: # circle equation: x^2+y^2=r^2\n",
    "            in_circle += 1 # inside the circle\n",
    "        n -= 1\n",
    "        \n",
    "    return 4 * in_circle / total\n",
    "\n",
    "estimate_pi()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Visualizing the profile with snakeviz\n",
    "```bash\n",
    "conda install snakeviz\n",
    "```\n",
    "\n",
    "and load the extension manually in the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext snakeviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%snakeviz estimate_pi()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"files/snakeviz.png\" width=350>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://jiffyclub.github.io/snakeviz/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def estimate_pi(n = 10000000):\n",
    "    in_circle = 0\n",
    "    total = n\n",
    "    \n",
    "    while n != 0:\n",
    "        prec_x = random()\n",
    "        prec_y = random()\n",
    "        if pow(prec_x, 2) + pow(prec_y, 2) <= 1: # circle equation: x^2+y^2=r^2\n",
    "            in_circle += 1 # inside the circle\n",
    "        n -= 1\n",
    "        \n",
    "    return 4 * in_circle / total\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Algorithmic optimization\n",
    "Our code is easy to read, but slow, because of:\n",
    "* while loop\n",
    "* function calls: pow()\n",
    "\n",
    "We can replace the whole function with one line!:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_pi_oneliner(n=1e7):\n",
    "    return 4 * sum(1 for _ in range(int(n)) if random()**2 + random()**2 <= 1) / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "stats_oneliner = %prun -r -q estimate_pi_oneliner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "stats_oneliner.sort_stats('tottime').print_stats(3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -r 2 -n 5 estimate_pi_oneliner()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From 3.67 to 2.45 seconds: Over 30% improvement!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**What did we do?**\n",
    "* <span style=\"color:green\">Replace `pow()` with `**`</span>\n",
    "* <span style=\"color:green\">Replace `while` with `sum(.. for .. in range(n))`</span>\n",
    "* <span style=\"color:red\">Made the function really hard to read for humans</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a **generator expression**: `sum(.. for .. in range(n))`\n",
    "\n",
    "A *what??*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Iterables: Everything that you can use in a for loop. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mylist = [0, 1, 4]\n",
    "for i in mylist:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mylist = [x*x for x in range(3)]\n",
    "for i in mylist:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Generators are iterators, but *you can only iterate over them once*. It’s because they do not store all the values in memory, they generate the values on the fly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mygenerator = (x*x for x in range(3))\n",
    "for i in mygenerator:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in mygenerator:\n",
    "    print(i)\n",
    "# Nothing happens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generators are useful if you run into memory issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### You can create a generator with yield\n",
    "Yield is a keyword that is used like return, except the function will return a generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createGenerator():\n",
    "    mylist = range(3)\n",
    "    for i in mylist:\n",
    "        yield i*i\n",
    "\n",
    "mygenerator = createGenerator() # create a generator\n",
    "print(mygenerator) # mygenerator is an object!\n",
    "\n",
    "for i in mygenerator:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first time the for calls the generator object created from your function, it will run the code in your function from the beginning until it hits yield, then it’ll return the first value of the loop. Then, each other call will run the loop you have written in the function one more time, and return the next value, until there is no value to return."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Optimization through vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All our operations are still inside the \"loop\":\n",
    "```python\n",
    "sum(1 for _ in range(int(n)) if random()**2 + random()**2 <= 1)\n",
    "```\n",
    "    \n",
    "So we are calling `random()` 2*n times, and we call `if` n times. Do we really need to?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Vectorized version, using numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def estimate_pi_vectorized(n=10000000):\n",
    "    xy = np.random.rand(n, 2)\n",
    "    inside = np.sum(xy[:, 0]**2 + xy[:, 1]**2 <= 1)\n",
    "    return 4 * inside / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%timeit -r 2 -n 5 estimate_pi_vectorized()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.67 seconds to 0.3 seconds: We are 12 times faster than in the beginning!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Memory profiling\n",
    "Juggling with large data sets involves having a clear sight of memory consumption and allocation processes going on in the background.\n",
    "\n",
    "After installing the memory profiler,\n",
    "```bash\n",
    "conda install memory_profiler \n",
    "```\n",
    "\n",
    "we can explore memory usage with `%memit`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%memit estimate_pi_vectorized()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This is a lot of memory. When we allocate things differently, we can reduce it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_pi_vectorized_oneliner(n=10000000):\n",
    "    return np.sum(np.random.random(n)**2 + np.random.random(n)**2 <= 1) / n * 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%memit estimate_pi_vectorized_oneliner()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Also, we improved runtime:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -r 2 -n 5 estimate_pi_vectorized_oneliner()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.67 seconds to 0.227 seconds: We are now 16 times faster than in the beginning!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Optimization through cheating: Running another algorithm\n",
    "Using our monte carlo method, we estimated $\\pi$ to 3.1426944 with a relative error of 0.035% in 227ms.\n",
    "\n",
    "There are however different calculations tackling the issue in a substantially more productive way. The biggest lift to any programming execution will be by changing the general way of tackling the problem. Unsurprisingly, this is the hardest change to achieve as upgrade and revamp of your coding is required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A very fast method is the [Chudnovsky algorithm](https://www.craig-wood.com/nick/articles/pi-chudnovsky/) which was published by the Chudnovsky brothers in 1989 and appears in the following form: $\\frac{1}{\\pi} = 12\\sum_{k=0}^\\infty \\frac{(-1)^k(6k)!(13591409+545140134k)}{(3k)!(k!)^3 640320^{3k+3/2}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Profiling this method results in: 13.6 µs ± 72 ns per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
    "\n",
    "Which is 270,000 times faster!!! Also, we get 100 digits of pi, not just 8."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summary of  most effective optimization techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Use better algorithms and data structures\n",
    "* Avoid loops\n",
    "* Vectorize (numpy)\n",
    "* Avoid function calls and dot notation\n",
    "* Memory: Use views, not copies\n",
    "* Memory: Use generators\n",
    "* Use compiled code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Use better algorithms and data structures, avoid loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* General explanation of time complexity: https://towardsdatascience.com/understanding-time-complexity-with-python-examples-2bda6e8158a7\n",
    "* Time complexity of Python data structures: https://wiki.python.org/moin/TimeComplexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Example: Unique common elements\n",
    "Suppose you were given two lists `xs` and `ys` and asked to find the unique elements in common between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = np.random.randint(0, 1000, 10000)\n",
    "ys = np.random.randint(0, 1000, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is easy to solve using a nested loop\n",
    "\n",
    "def common1(xs, ys):\n",
    "    \"\"\"Using lists.\"\"\"\n",
    "    zs = []\n",
    "    for x in xs:\n",
    "        for y in ys:\n",
    "            if x==y and x not in zs:\n",
    "                zs.append(x)\n",
    "    return zs\n",
    "\n",
    "%timeit -n1 -r1 common1(xs, ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# However, it is much more efficient to use the set data structure, avoiding loops\n",
    "\n",
    "def common2(xs, ys):\n",
    "    return list(set(xs) & set(ys))\n",
    "\n",
    "%timeit -n1 -r1 common2(xs, ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Avoid function calls and dot notation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example: Looped function calls\n",
    "In the following example, the function `inner` is called for each element in the list. The overhead of the function call and the argument checking is multiplied 100000 times. (From https://nyu-cds.github.io/python-performance-tips/04-functions/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 0\n",
    "def inner(i):\n",
    "    global x\n",
    "    x = x + i\n",
    "    \n",
    "def outer1():\n",
    "    for i in range(100000): \n",
    "        inner(i)\n",
    "        \n",
    "%timeit outer1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Here instead, the loop is moved inside the aggregate function so that the function is only called once instead of 100000 times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 0\n",
    "def aggregate(list):\n",
    "    global x\n",
    "    for i in list:\n",
    "        x = x + i\n",
    "\n",
    "def outer2():\n",
    "    aggregate(range(100000))\n",
    "    \n",
    "%timeit outer2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Example: Avoid dot notation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slow:\n",
    "\n",
    "```python\n",
    "for i in range(n):\n",
    "    myObj.func(i)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fast:\n",
    "\n",
    "```python\n",
    "myfunc = myObj.func\n",
    "for i in range(n):\n",
    "    myfunc(i)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Use compiled code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cython\n",
    "http://docs.cython.org/en/latest/src/tutorial/cython_tutorial.html\n",
    "\n",
    "Cython is Python with C data types.\n",
    "\n",
    "Cython is Python: Almost any piece of Python code is also valid Cython code. The Cython compiler will convert it into C code which makes equivalent calls to the Python/C API.\n",
    "\n",
    "### Pypy\n",
    "https://pypy.org/\n",
    "\n",
    "Alternative implementaiton of Cython using a just-in-time compiler instead of an interpreter, often making it run faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing code usually comes at the cost of code readability and maintainability!\n",
    "Think twice if you really need to sacrifice it.\n",
    "\n",
    "This code (from last class) might be slow to call, but is well designed and perfectly readable. If the implementation of a method if obvious like here, you did a good job in terms of object-oriented design:\n",
    "\n",
    "```python\n",
    "    def winsServe(self):\n",
    "        \"\"\"Returns a Boolean that is true with probability self.prob\"\"\"\n",
    "        return random() <= self.prob\n",
    "\n",
    "    def incScore(self):\n",
    "        \"\"\"Add a point to this player's score\"\"\"\n",
    "        self.score = self.score + 1\n",
    "\n",
    "    def getScore(self):\n",
    "        \"\"\"Returns this player's current score\"\"\"\n",
    "        return self.score\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
